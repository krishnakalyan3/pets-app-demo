{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b19ae16-4056-4074-adcd-4877f418bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download jessicali9530/stanford-dogs-dataset -p . --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "724a33c1-231b-46a1-b7c5-08ca6f706a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03af1376-dade-448e-8388-3a9b86998d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchmetrics import Accuracy, F1Score, MetricCollection\n",
    "from pytorch_lightning.callbacks import RichProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f740d5b7-f0c4-46c3-8d12-0d139d6fd795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "698d580c-0c56-4d34-8b85-a34f4df9ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3ced883-4d9e-4c5e-8742-bf15b6d53649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import timm\n",
    "import wandb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "258230ab-ba7b-453c-bf6e-d209976f3ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'08/31/22 08:29:47'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "current_time = datetime.now().strftime(\"%D %H:%M:%S\"); current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d750cf9-0cfc-438e-802a-295498856687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1111\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkrishnakalyan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/krishna/pets/notebooks/wandb/run-20220831_082949-3d8vsp8o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/krishnakalyan/pets/runs/3d8vsp8o\" target=\"_blank\">classification-08/31/22 08:29:47</a></strong> to <a href=\"https://wandb.ai/krishnakalyan/pets\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Create a new poject in W&B\n",
    "seed_everything(1111)\n",
    "wandb_logger = WandbLogger(project=\"pets\", name=f\"nbs-{current_time}\", log_model=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "813d99a9-8296-4f72-9770-7dd3074ecd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(files, target_dict, split_pct = .2):\n",
    "    split_class = {j:0 for j in dset.target_dict}\n",
    "    train_idx = []\n",
    "    val_idx = []\n",
    "    \n",
    "    # Calculate number of images perclass\n",
    "    for i in files:\n",
    "        class_name = i.parent.name\n",
    "        split_class[class_name] += 1\n",
    "    \n",
    "    # Calculate percentage\n",
    "    for i in split_class:\n",
    "        split_class[i] = int(split_class[i]*.2)\n",
    "    \n",
    "    for idx, i in enumerate(files):\n",
    "        class_name = i.parent.name\n",
    "        \n",
    "        if split_class[class_name] == 0:\n",
    "            train_idx.append(idx)\n",
    "        else:\n",
    "            val_idx.append(idx)\n",
    "            split_class[class_name] -= 1\n",
    "    \n",
    "    return train_idx, val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bda5473-73db-44e5-8266-29f7da24d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = A.Compose([\n",
    "            A.Resize(512, 512),\n",
    "            A.HorizontalFlip(0.5),\n",
    "            A.VerticalFlip(),\n",
    "            A.RandomRotate90(),\n",
    "            A.Rotate(10),\n",
    "            A.ColorJitter(0.2,0.2,0,0),\n",
    "            A.Normalize(),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de9dbcf4-a8f6-4c4a-bb5f-6c011293240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pets(Dataset):\n",
    "    def __init__(self, \n",
    "                 data_dir: str = None,\n",
    "                 transforms = T.Compose([T.Resize((225, 225)), T.ToTensor(), T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])):\n",
    "        super().__init__()\n",
    "        self.files = [i for i in data_dir.glob(\"*/*.jpg\")]\n",
    "        self.transforms = transforms\n",
    "        self.target_dict = {k.name:i for i,k in enumerate(data_dir.iterdir())}\n",
    "        self.inverse_target = {i:k.name for i,k in enumerate(data_dir.iterdir())}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path  = self.files[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = np.array(img)\n",
    "            img = self.transforms(image=img)['image']\n",
    "\n",
    "        return {'image':img, 'target': self.target_dict[img_path.parent.name]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f26e2419-df28-4121-8f13-3f45bdf85cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\"images/Images/\")\n",
    "dset = Pets(data_dir=ROOT, transforms=aug)\n",
    "classes = len(dset.target_dict)\n",
    "class_names = list(dset.target_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a112ce2-7342-416d-b473-7b900976705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = is_valid(dset.files, dset.target_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44ca84cc-6679-449f-8096-c9bee8f012fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetsDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir, batch_size, index, dset):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        (self.train_idx, self.val_idx) = index\n",
    "        self.dset = dset\n",
    "        self.transforms = T.Compose([T.Resize((512, 512)), T.ToTensor(), T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dset = Subset(dset, self.train_idx)\n",
    "        return DataLoader(train_dset, batch_size=self.batch_size, pin_memory=True, shuffle=True, num_workers=2)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        val_dset = Subset(dset, self.val_idx)\n",
    "        return DataLoader(val_dset, batch_size=self.batch_size, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5437790-06d6-4ff5-bc0f-d820fb40e78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pets = PetsDataModule(ROOT, 64, index, dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c168ce39-1f91-4a4f-9aef-ee2165c6a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Images\n",
    "size = 7\n",
    "samples = np.random.randint(0, high=20580, size=size)\n",
    "sample_images = [dset[i][\"image\"] for i in samples]\n",
    "sample_caption = [dset.inverse_target[dset[i][\"target\"]] for i in samples]\n",
    "wandb_logger.log_image(key=\"samples\", images=sample_images, caption=sample_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "234aac43-0289-4978-9cb2-ea14df6326b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(nn.Module):\n",
    "    def __init__(self, model_name='tf_efficientnet_b0_ns', num_classes=classes, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        \n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        in_features = self.model.get_classifier().in_features\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9d9682f-cecc-4ebd-8bdc-5f2c71133175",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitClassifier(pl.LightningModule):\n",
    "    def __init__(self, learning_rate):\n",
    "        super().__init__()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.train_metrics = MetricCollection({\"train_acc\": Accuracy(num_classes=classes, average=\"micro\", multiclass=True),\n",
    "                                               \"train_f1\": F1Score(num_classes=classes, average=\"macro\", multiclass=True)})\n",
    "        self.val_metrics = MetricCollection({\"val_acc\": Accuracy(num_classes=classes, average=\"micro\", multiclass=True),\n",
    "                                             \"val_f1\": F1Score(num_classes=classes, average=\"macro\", multiclass=True)\n",
    "                                            })\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = LitModel()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = batch['image']\n",
    "        y = batch['target']\n",
    "        y_hat = self.model(x)\n",
    "\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        acc = self.train_metrics(y_hat, y)\n",
    "\n",
    "        logs = {'train_loss': loss, \n",
    "                'train_accuracy': self.train_metrics[\"train_acc\"], \n",
    "                \"train_f1\": self.train_metrics[\"train_f1\"]}\n",
    "    \n",
    "        self.log_dict(\n",
    "            logs,\n",
    "            on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = batch['image']\n",
    "        y = batch['target']\n",
    "        y_hat = self.model(x)        \n",
    "        loss = self.criterion(y_hat, y)\n",
    "        acc = self.val_metrics(y_hat, y)\n",
    "\n",
    "        logs = {'val_loss': loss, \n",
    "                'val_accuracy': self.val_metrics[\"val_acc\"], \n",
    "                \"val_f1\": self.val_metrics[\"val_f1\"]}\n",
    "\n",
    "        self.log_dict(\n",
    "            logs,\n",
    "            on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=(self.learning_rate))\n",
    "        scheduler = ReduceLROnPlateau(optimizer, 'min', patience = 3)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"val_f1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e38961ef-8799-420f-99d1-98fda8c070ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitClassifier(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47860fd6-700f-4bfb-b746-aa048780e0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=300, \n",
    "                     accelerator='auto',\n",
    "                     devices=1, \n",
    "                     precision=16,\n",
    "                     enable_progress_bar=True,\n",
    "                     callbacks=[RichProgressBar()],\n",
    "                     logger=wandb_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d055be-c245-4ed9-a8f0-0aff67c9a02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0   </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">╺━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">252/322</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:05:23 • 0:01:57</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">0.60it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 2.1 v_num: sp8o </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0   \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━\u001b[0m \u001b[37m252/322\u001b[0m \u001b[38;5;245m0:05:23 • 0:01:57\u001b[0m \u001b[38;5;249m0.60it/s\u001b[0m \u001b[37mloss: 2.1 v_num: sp8o \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, pets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ee86d8-3861-4a97-a516-b75ed48e46f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c6f37-94e3-43fd-98f4-36325db29037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
